{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jpx_final_submission.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPhammQc/iauoe7yopNtok2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jack-Hayes/datascience/blob/main/jpx_func.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcDq5kS2nvJD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
        "from sklearn.metrics import mean_squared_error as mse"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jpx_tokyo_market_prediction\n",
        "env = jpx_tokyo_market_prediction.make_env()\n",
        "iter_test = env.iter_test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "oy7ax4WP6Lb7",
        "outputId": "0b753bd2-fd14-4c5c-9503-ffacd462b0be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-ace374866e8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mjpx_tokyo_market_prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjpx_tokyo_market_prediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0miter_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'jpx_tokyo_market_prediction'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for (prices, options, financials, trades, secondary_prices, sample_prediction) in iter_test:\n",
        "  prices['Date'] = pd.to_datetime(prices['Date'])\n",
        "  raw_df = prices.sort_values(by='Date', ignore_index=True)\n",
        "  raw_df['AdjClose'] = raw_df['Close']*raw_df['AdjustmentFactor']\n",
        "  raw_df['AdjOpen'] = raw_df['Open']*raw_df['AdjustmentFactor']\n",
        "  raw_df['Diff'] = raw_df['High']-raw_df['Low']\n",
        "  raw_df['PercGain'] = ((raw_df['AdjClose']-raw_df['AdjOpen'])/raw_df['AdjOpen'])\n",
        "\n",
        "  data = raw_df[['Date','SecuritiesCode','Diff', 'Volume','PercGain']]\n",
        "  codes = data['SecuritiesCode'].unique()\n",
        "\n",
        "  mms = MinMaxScaler(feature_range=(0,100))\n",
        "  data['Diff'] = mms.fit_transform(data['Diff'].values.reshape(-1,1))\n",
        "  data['Volume'] = mms.fit_transform(data['Volume'].values.reshape(-1,1))\n",
        "  data['PercGain'] = mms.fit_transform(data['PercGain'].values.reshape(-1,1))\n",
        "\n",
        "  def ranking_tplus2(data, current_date, days=30, codes=codes):\n",
        "    mses = []\n",
        "    ranking_dict = dict([])\n",
        "\n",
        "    df = pd.DataFrame(columns = ['Date', 'SecuritiesCode', 'Ratio', 'Rank'])\n",
        "\n",
        "    def stds(data, codes):\n",
        "      std_list = []\n",
        "      for i in range(0, len(codes)):\n",
        "        newdat = data[data.SecuritiesCode == (codes[i])]\n",
        "        if np.isnan(newdat).sum().sum() > 0:\n",
        "          newdat = newdat.fillna(method='Bfill')\n",
        "          newdat = newdat.fillna(method='Ffill')\n",
        "        std = np.std(newdat['PercGain'])\n",
        "        std_list.append(std)\n",
        "      return std_list\n",
        "\n",
        "    std_list = stds(data, codes)\n",
        "      \n",
        "    for l in range(0, len(codes)):\n",
        "      new_dat = data[data.SecuritiesCode == (codes[l])].reset_index().drop(columns='index')\n",
        "      if new_dat.index[new_dat.Date == current_date].tolist() == []:\n",
        "        print('Stock id', codes[l], 'does not have any data for day', current_date)\n",
        "      else:\n",
        "        idx = (new_dat.index[new_dat.Date == current_date].tolist())[0]-days-2\n",
        "        new_dat = new_dat[['Diff', 'Volume', 'PercGain']]\n",
        "\n",
        "        for k in range(0, len(new_dat)):\n",
        "          if np.isnan(new_dat.iloc[k]).sum() > 0:\n",
        "            new_dat = new_dat.fillna(method='Bfill')\n",
        "            new_dat = new_dat.fillna(method='Ffill')\n",
        "\n",
        "        xtrain, ytrain = [], []\n",
        "        for i in range(days, (len(new_dat)-2)):\n",
        "          xtrain.append(new_dat[(i-days):i])\n",
        "          ytrain.append(new_dat.iloc[i+2][2])\n",
        "        xtrain, ytrain = np.array(xtrain), np.array(ytrain)\n",
        "        xtrain = np.reshape(xtrain, (xtrain.shape[0], 1, xtrain.shape[1]*xtrain.shape[2]))\n",
        "\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=3e-4)\n",
        "        model = Sequential()\n",
        "        model.add(LSTM(units=64, return_sequences=True, input_shape=(xtrain.shape[1], xtrain.shape[2])))\n",
        "        model.add(Dropout(0.1))\n",
        "        model.add(LSTM(units=64, return_sequences=False))\n",
        "        model.add(Dropout(0.1))\n",
        "        model.add(Dense(units=32))\n",
        "        model.add(Dense(units=1))\n",
        "        model.compile(optimizer=optimizer, loss='mse')\n",
        "\n",
        "        model.fit(xtrain, ytrain, epochs=40, batch_size=64, validation_split=0.25, shuffle=True, verbose=0)\n",
        "\n",
        "        onextest = xtrain[idx] \n",
        "        oneytest = ytrain[idx] \n",
        "\n",
        "        oneypred = model.predict(np.array([onextest]))\n",
        "        oneypred = oneypred.flatten()\n",
        "\n",
        "        check = ytrain[idx+1]\n",
        "        per_gain_diff = oneypred-check\n",
        "\n",
        "        ratio = per_gain_diff/std_list[l]\n",
        "        penalty = (mse(model.predict(xtrain), ytrain))/100\n",
        "        ratio = ratio-penalty\n",
        "\n",
        "        df = df.append({'Date': current_date, 'SecuritiesCode': codes[l], 'Ratio': ratio}, ignore_index=True)\n",
        "\n",
        "    df.sort_values(by=['Ratio'], ascending=False)\n",
        "    for i in range(0,200):\n",
        "      df.at[i, 'Rank'] = i\n",
        "      df.at[(i+1800), 'Rank'] = (i+1800)\n",
        "    df = df.dropna()\n",
        "\n",
        "    return df\n",
        "\n",
        "    prediction = ranking_tplus2(data=data, current_date='2022-05-27')\n",
        "\n",
        "    prediction[['Date', 'SecuritiesCode', 'Rank']] = np.arange(len(prediction))\n",
        "    env.predict(prediction)"
      ],
      "metadata": {
        "id": "MHXR4nj56Qpi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}